{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6ob0KFjqrFx",
        "outputId": "9f4407cb-da4d-44e3-94fd-20cdfb2cdcc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.35.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wngil979pd6C",
        "outputId": "614bb882-ea7a-4a66-b983-e25e82423800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm ready to assist you as a virtual data science consultant. Please provide the necessary information, and I'll deliver the results in the standardized format:\n",
            "\n",
            "`Script Name | Schema | Table | Source Columns Name | Transformed Column Name | Business Rule | Comment`\n",
            "\n",
            "Go ahead and provide the details, and I'll generate the mapping output. If there are no values to put in a column, I'll simply write `null`."
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
        "  api_key = \"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\"\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"meta/llama3-70b-instruct\",\n",
        "  messages=[{\"role\":\"user\",\"content\":\"as a virtual data science consultant specializing in source-to-target mapping, consistently delivers results in the following format:\\n\\nScript Name | Schema | Table | Source Columns Name | Transformed Column Name | Business Rule | Comment\\n\\nThis standardized format streamlines the understanding and implementation of data mappings, ensuring clarity and effectiveness in the process, if there are no values to put in the column, just write null and only output the mapping without any additional text or generation.\\n\"}],\n",
        "  temperature=0.5,\n",
        "  top_p=1,\n",
        "  max_tokens=1024,\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "  if chunk.choices[0].delta.content is not None:\n",
        "    print(chunk.choices[0].delta.content, end=\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "\n",
        "def interact_with_openai(text_input):\n",
        "    client = OpenAI(\n",
        "        base_url=\"https://integrate.api.nvidia.com/v1\",\n",
        "        api_key=\"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\"\n",
        "    )\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"meta/llama3-70b-instruct\",\n",
        "        messages=[{\"role\": \"user\", \"content\": text_input}],\n",
        "        temperature=0.5,\n",
        "        top_p=1,\n",
        "        max_tokens=1024,\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    generated_text = \"\"\n",
        "    for chunk in completion:\n",
        "        if chunk.choices[0].delta.content is not None:\n",
        "            generated_text += chunk.choices[0].delta.content\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "# Example usage:\n",
        "user_input = input(\"Enter your text input: \")\n",
        "generated_response = interact_with_openai(user_input)\n",
        "\n",
        "# Save to Excel\n",
        "output_df = pd.DataFrame({'Generated Text': [generated_response]})\n",
        "output_df.to_excel('generated_output.xlsx', engine='openpyxl', index=False)\n",
        "\n",
        "print(\"Generated text saved to generated_output.xlsx\")\n"
      ],
      "metadata": {
        "id": "MgsOTXXUuP26"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}